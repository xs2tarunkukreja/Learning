# Responsible AI
Bias
Fair
Accuracy

## Challenge or Risk
Toxicity
    LLM return responses that can be potentially harmful or discriminatory toward protected groups or protected attributes.
    Mitigate - 
        Careful curation of training data
        Train guardrail models to filter out unwanted content.
        Diverse group of human annotators.
Hallucination
    Things are simply not true. LLM generate factually incorrect content.
    Mitigate -
        Educate users about how gnerate AI works
        Add Disclaimer
        Augment LLMs with independent, verified citation DB.
        Define intended/unintended use cases.
Intellectual Property
    Ensure people aren't plagiarizing, make sure there aren't any copyright issues.
    Mitigate -
        mix the technology, policy and legal mechanism.
        Machine "unlearning"
        Filtering and Blocking approaches.

## Responsibly build and use GenAI models
Define use cases: the more specific and narrow, the better.
Access risk for each use case.
Evaluate performance for each use case.
Iterate over entire AI Lifecycle.